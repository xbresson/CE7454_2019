{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 01 : Cross-entropy loss -- exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Google Colaboratory\n",
    "import sys, os\n",
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    file_name = 'cross_entropy_exercise.ipynb'\n",
    "    import subprocess\n",
    "    path_to_file = subprocess.check_output('find . -type f -name ' + str(file_name), shell=True).decode(\"utf-8\")\n",
    "    print(path_to_file)\n",
    "    path_to_file = path_to_file.replace(file_name,\"\").replace('\\n',\"\")\n",
    "    os.chdir(path_to_file)\n",
    "    !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Cross Entropy Criterion and call it criterion. The command is nn.CrossEntropyLoss()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=  # COMPLETE HERE\n",
    "\n",
    "print(criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suppose that there only two classes (class 0 and class 1).\n",
    "### Suppose we have a batch of three data points: \n",
    "### ${\\bf x^{(0)}}$ belongs to class 0\n",
    "### ${\\bf x^{(1)}}$belongs to class 1\n",
    "### ${\\bf x^{(2)}}$ belongs to class 1\n",
    "### Put the labels of each of these point a LongTensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = # COMPLETE HERE\n",
    "\n",
    "print(labels,labels.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a batch of scores: each row corresponds to the scores associated with a data point. So your batch of scores should look likes something like:\n",
    "\n",
    "$$\n",
    "\\text{scores} \\;\\; = \\;\\; \\begin{bmatrix}\n",
    "s_0^{(0)} & s_1^{(0)} & \\\\\n",
    "s_0^{(1)} & s_1^{(1)} & \\\\\n",
    "s_0^{(2)} & s_1^{(2)} & \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "### You will need to create a tensor of the form torch.Tensor( [ [ ], [ ], [ ] ] ). Don't forget the extra square brackets!\n",
    "\n",
    "### Choose scores that will leads to a loss very close to zero, let say around or smaller than 0.05 (indicating that the scores are very good with respect to the labels). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores =  # COMPLETE HERE\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display your batch of scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "utils.display_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the criterion to compute the average loss on this batch -- it needs to be around or smaller than 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_loss =  # COMPLETE HERE\n",
    "\n",
    "print(average_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
